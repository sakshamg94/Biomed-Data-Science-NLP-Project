{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 271 CUI2VEC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define imports\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy import asarray\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import gensim.downloader as api\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read in relevant Data Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the files below are in the same directory as your jupyter file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "PATIENT_DATA_FILE = 'B220_SAA_v1.csv'\n",
    "CLEANED_LABELS_FILE = 'ICD_Label_Cleaned_Oct_25.csv'\n",
    "CODE_DESC_FILE = 'BIODS220_ICD_Dx_10_9_v7 - icd_dx_10_9_v7.csv'\n",
    "LANG_MODEL = 'CUI2VEC'\n",
    "CUI2VEC_MODEL = 'CUI2Vec_embedding.pickle'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_to_dict(file_path: str, key: int, value: int):\n",
    "    ret_dict = {}\n",
    "    with open(file_path, newline='') as csvfile:\n",
    "        data = csv.reader(csvfile, delimiter=',')\n",
    "        for row in data:\n",
    "            ret_dict[row[key]] = row[value]\n",
    "    print(\"Reading {} complete!\".format(file_path))\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_dict():\n",
    "    category_dict = {\n",
    "        'Circulatory': 0,\n",
    "        'Dermatologic': 4,\n",
    "        'Endocrine & Immune': 6,\n",
    "        'Gastrointestinal': 1,\n",
    "        'Genitourinary': 1, \n",
    "        'Hematologic': 4,\n",
    "        'Infectious': 6,\n",
    "        'Injury': 2,\n",
    "        'Injury & Poisoning': 2,\n",
    "        'Poisoning': 2,\n",
    "        'Musculoskeletal': 2,\n",
    "        'Neurologic': 3,\n",
    "        'Other': 4,\n",
    "        'Obstetric': 5,\n",
    "        'Neoplastic': 4,\n",
    "        'Psychiatric': 3,\n",
    "        'Respiratory': 0,\n",
    "        'Substance use': 2}\n",
    "    #use to_categorical()\n",
    "    return category_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ICD_Label_Cleaned_Oct_25.csv complete!\n",
      "Reading BIODS220_ICD_Dx_10_9_v7 - icd_dx_10_9_v7.csv complete!\n"
     ]
    }
   ],
   "source": [
    "# Create labels dict i.e. code -> label, i.e. A840 -> 'Neurologic'\n",
    "label_dict = read_csv_to_dict(CLEANED_LABELS_FILE, key=0, value=1)\n",
    "\n",
    "# Create descriptions dict i.e. code -> description\n",
    "codes_dict = read_csv_to_dict(CODE_DESC_FILE, key=0, value=2)\n",
    "\n",
    "# Create dict for label to int\n",
    "category_dict = get_category_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create one-hot feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of reducing feature space, we are only including three features in our embedding. Future iterations of our embeddings will include more features, such as the patient's county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_hot(patient_data):\n",
    "    # Creates one-hot vectors\n",
    "    columns_to_one_hot = ['Sex','Race']\n",
    "    one_hot = pd.get_dummies(patient_data[columns_to_one_hot])\n",
    "    \n",
    "    ordinal_columns = ['Age']\n",
    "    one_hot = pd.concat([patient_data[ordinal_columns], one_hot], axis=1)\n",
    "    \n",
    "    # Normalize age\n",
    "    x = one_hot.Age.values.reshape(-1,1)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    one_hot.Age = x_scaled\n",
    "    \n",
    "    return one_hot.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in patient_data took 49.75160312652588\n",
      "Creating one-hot encodings took 9.033980369567871\n",
      "(27977932, 11)\n"
     ]
    }
   ],
   "source": [
    "# Read in patient_data - takes a few mins\n",
    "patient_read_start = time.time()\n",
    "patient_data = pd.read_csv(PATIENT_DATA_FILE, dtype=str, usecols=['ID', 'Sex','Race','Age', 'Date','Dx10_prin'])\n",
    "print(\"Reading in patient_data took {}\".format(time.time() - patient_read_start))\n",
    "\n",
    "# One-hot encode visit features\n",
    "one_hot_start = time.time()\n",
    "one_hot = create_one_hot(patient_data)\n",
    "print(\"Creating one-hot encodings took {}\".format(time.time() - one_hot_start))\n",
    "print(one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Dx10_prin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-05</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>S300XXA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>36</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>N938</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>36</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>F10129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>R0789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-29</td>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>N390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  ID        Date Age Sex      Race Dx10_prin\n",
       "0  1  2016-06-05  35   F     White   S300XXA\n",
       "1  1  2017-07-16  36   F     White      N938\n",
       "2  1  2017-08-15  36   F     White    F10129\n",
       "3  1  2018-07-12  37   F     White     R0789\n",
       "4  2  2015-12-29  42   M  Hispanic      N390"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (num_patients, 311)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Embed ICD Codes + concat with one-hot vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the presaved cui2vec embeddings dictionary (ICD10_Code_first_3_chars : float_embedding_vector of size 300)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given the embedding from the pretrained cui2vec embeddings dictionary (in a pickle) that stores the first three chars of the ICD10 code and its corresponding embeddings vector of floats. If there is no embedding for the sentence then return the embedding for the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle_in = open(CUI2VEC_MODEL, 'rb')\n",
    "EMBEDDINGS = pickle.load(pickle_in)\n",
    "pickle_in.close()\n",
    "CONST_EMBEDDING_SIZE = 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an ICD code, we retrieve the embedding (300x1). We use dynamic programming to save embeddings. Often, only the first three characters of an ICD code are enough to determine the general diagnosis. Longer codes will only have slightly different descriptions (if at all). Thus, to reduce computational complexity, we store the first three characters of ICD codes. Future ICD codes that share the same first three characters will automatically use the same embedding, regardless of any remaining characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def code_to_embedding(code):\n",
    "    try:\n",
    "        embedding = EMBEDDINGS[str(code)]\n",
    "    except:\n",
    "        try:\n",
    "            embedding = EMBEDDINGS[str(code[:3])]\n",
    "        except:\n",
    "            embedding = np.zeros((CONST_EMBEDDING_SIZE,))\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each row of ICD Codes (i.e ['E839', 'SA920']), we retrieve the corresponding embeddings. For patient visits with n ICD Codes where n>1, we give 0.75 weight to the primary ICD code and 0.25/n-1 weight to the remaining (secondary) codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIMARY_WEIGHT = 0.5\n",
    "SECONDARY_WEIGHT = 0.5\n",
    "\n",
    "def row_to_embedding(input_row):\n",
    "    \"\"\"\n",
    "    input_row: A list of ICD10 codes\n",
    "    returns a 300x1 embedding\n",
    "    \"\"\"\n",
    "    n = len(input_row)\n",
    "    code = input_row[0]\n",
    "    # Primary ICD code:\n",
    "    primary_embedding = code_to_embedding(code)\n",
    "    if n < 2: return primary_embedding\n",
    "    \n",
    "    # Subsequent ICD codes:\n",
    "    secondary_embedding = None\n",
    "    for i in range(1, n):\n",
    "        code = input_row[i]\n",
    "        curr_embed = code_to_embedding(code)\n",
    "        if secondary_embedding is None:\n",
    "            secondary_embedding = curr_embed\n",
    "        else:\n",
    "            secondary_embedding = np.sum([secondary_embedding, curr_embed], axis=0)\n",
    "    \n",
    "    final_embedding = np.sum([primary_embedding * PRIMARY_WEIGHT, secondary_embedding * (SECONDARY_WEIGHT/(n-1))], axis=0)\n",
    "    \n",
    "    return final_embedding\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the patient visit csv file again and create embeddings for each visit as we read the file. For each visit, we have already computed the one-hot vector encoding for categorical and ordinal variables. Here, we combine those encodings with ICD_10 code embeddings. To reduce model complexity, we limit the number of patients (not total visits) for which to create embeddings. Here, we are working under the assumption that all visits for a patient appear one after the other in the csv file, thus, we can stop reading from the file once `patient id > num_patients`. Takes a few mins to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of patients with none of their ICD10 codes in pretrained embeddings: (2,)\n",
      "Shape of embeddings: (215240,311)\n",
      "Shape of patient_visit: (215240,2)\n"
     ]
    }
   ],
   "source": [
    "NUM_PATIENTS = .1e6\n",
    "\n",
    "def get_visit_embedding(input_file_path: str):\n",
    "    num_invalid_patient_codes = 0\n",
    "    start_time = time.time()\n",
    "    embeddings = []\n",
    "    patient_visit = []\n",
    "    max_len = 0\n",
    "#     patient_visit = {\n",
    "#         1 : [[1, embed],[4, embed],[2,embed]],\n",
    "#         2 : [[embed],[embed],....],\n",
    "#         .\n",
    "#         .\n",
    "#         .\n",
    "#     }\n",
    "    with open(input_file_path, newline='') as csvfile:\n",
    "        data = csv.reader(csvfile, delimiter=',')\n",
    "        count = 0\n",
    "        for row in data: # <- top to bottom\n",
    "            if count == 0: # Skip the first row\n",
    "                count += 1\n",
    "                continue\n",
    "            \n",
    "            if int(row[0]) > NUM_PATIENTS: # Used to limit num patients, reducing model space\n",
    "                break\n",
    "                \n",
    "            ICD_code_embeddings = row_to_embedding([entry for entry in row[16:41] if entry is not ''])\n",
    "            # check which patients had none of their ICD 10 codes in the pretrained embeddings model (CUI2VEC)\n",
    "            if (not ICD_code_embeddings.any()): num_invalid_patient_codes+=1\n",
    "            \n",
    "            # Combine one-hot with w2v embeddings\n",
    "            visit_embedding = np.concatenate((one_hot[count-1, :], ICD_code_embeddings), axis=0)\n",
    "            embeddings.append(visit_embedding)\n",
    "            patient_visit.append([row[0], row[1]]) # store patient and visit info\n",
    "            \n",
    "            # Tracking progress\n",
    "            if count % 250000 == 0:\n",
    "                print(\"Completed {} visit embeddings in {}\".format(count, (time.time() - start_time)))\n",
    "            count +=1\n",
    "            \n",
    "    print(\"Number of patients with none of their ICD10 codes in pretrained embeddings: ({},)\".format(num_invalid_patient_codes))        \n",
    "    print(\"Shape of embeddings: ({},{})\".format(len(embeddings), len(embeddings[0])))\n",
    "    print(\"Shape of patient_visit: ({},{})\".format(len(patient_visit), len(patient_visit[0])))\n",
    "    embedding_vecs = np.array(embeddings)\n",
    "    result = np.hstack((np.array(patient_visit),embedding_vecs)) # patient id, visit id, embedding vector\n",
    "    return result, count-1, num_invalid_patient_codes\n",
    "\n",
    "embedding_dset, num_visits, num_invalid_patient_codes = get_visit_embedding(PATIENT_DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Get Labels (Adam's version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading in patient_data took 0.3386993408203125\n"
     ]
    }
   ],
   "source": [
    "# Read in patient_data - takes about a minute\n",
    "patient_read_start = time.time()\n",
    "patient_data = pd.read_csv(PATIENT_DATA_FILE, dtype=str, usecols=['ID', 'Sex','Race','Age', 'Date'], nrows = num_visits)\n",
    "print(\"Reading in patient_data took {}\".format(time.time() - patient_read_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_labels(patient_data):\n",
    "\n",
    "    patient_data['Date'] = pd.to_datetime(patient_data['Date'])  #convert date column to date-time type\n",
    "    y_diff = abs(patient_data.groupby(['ID'])['Date'].diff(periods=-1))\n",
    "    y_diff = y_diff.dt.days\n",
    "    y_label = []\n",
    "    for i in y_diff:\n",
    "        if pd.isnull(i):\n",
    "            y_label.append(2)\n",
    "        else:\n",
    "            if i <= 30:\n",
    "                y_label.append(1)\n",
    "            else:\n",
    "                y_label.append(0)\n",
    "    return y_label, len(y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating labels took 6.306676149368286\n"
     ]
    }
   ],
   "source": [
    "# Get y_dset\n",
    "label_start = time.time()\n",
    "y_dset, num_labels = get_y_labels(patient_data)\n",
    "print(\"Creating labels took {}\".format(time.time() - label_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(215240, 313)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34324"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(embedding_dset[:,0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures the number of labels corresponds to the number of patient visits\n",
    "assert(num_labels == num_visits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(215240, 314)\n"
     ]
    }
   ],
   "source": [
    "new_dset = np.hstack([embedding_dset, np.array(y_dset).reshape(len(y_dset),1)])\n",
    "print(new_dset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del embedding_dset, y_dset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "discards = np.not_equal(new_dset[:,-1].astype('float'),np.ones((len(new_dset),))*2.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dset = new_dset[discards]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(180916, 314)\n"
     ]
    }
   ],
   "source": [
    "print(new_dset.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34324"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(np.unique(new_dset[:,0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Save embeddings and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving embeddings took: 71.72887325286865\n"
     ]
    }
   ],
   "source": [
    "filename = 'embeddings_{}_binary.pickle'.format(LANG_MODEL)\n",
    "\n",
    "start_time = time.time()\n",
    "pickle_out = open(filename, 'wb')\n",
    "pickle.dump((embedding_dset, y_dset), pickle_out, protocol=4)\n",
    "pickle_out.close()\n",
    "print(\"Saving embeddings took: {}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'embeddings_{}.pickle'.format(LANG_MODEL)\n",
    "# start_time = time.time()\n",
    "# pickle_in = open(filename, 'rb')\n",
    "# embedding_dset, y_dset = pickle.load(pickle_in)\n",
    "# pickle_in.close()\n",
    "# print(\"Saving embeddings took: {}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "## collated_data = embedding_dset\n",
    "cols =  ['patient_id', 'visit_id'] + ['embed_vec'+ str(i) for i in range(new_dset.shape[1]-4)] + ['label']\n",
    "df = pd.DataFrame(data = collated_data, columns = cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clear variables\n",
    "collated_data = None\n",
    "new_dset = None\n",
    "embedding_dset = None\n",
    "y_dset = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the data types "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['patient_id'] = df['patient_id'].astype(str).astype('int64')\n",
    "df['visit_id'] = df['visit_id'].astype(str).astype('int64')\n",
    "for col in cols[2:-1]:\n",
    "    df[col] = df[col].astype(str).astype(np.float32)\n",
    "\n",
    "df['label'] = df['label'].astype(str).astype(np.int16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "patient_id        int64\n",
       "visit_id          int64\n",
       "embed_vec0      float32\n",
       "embed_vec1      float32\n",
       "embed_vec2      float32\n",
       "                 ...   \n",
       "embed_vec307    float32\n",
       "embed_vec308    float32\n",
       "embed_vec309    float32\n",
       "embed_vec310    float32\n",
       "label             int16\n",
       "Length: 314, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comment out the pickle dump/load sections below based on need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'patient_dataframe_{}_Binary.pkl'.format(LANG_MODEL)\n",
    "pickle_out = open(filename, 'wb')\n",
    "pickle.dump(df, pickle_out, protocol=4)\n",
    "pickle_out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = 'patient_dataframe_{}.pkl'.format(LANG_MODEL)\n",
    "# pickle_in = open(filename, 'rb')\n",
    "# df = pickle.load(pickle_in)\n",
    "# pickle_in.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>visit_id</th>\n",
       "      <th>embed_vec0</th>\n",
       "      <th>embed_vec1</th>\n",
       "      <th>embed_vec2</th>\n",
       "      <th>embed_vec3</th>\n",
       "      <th>embed_vec4</th>\n",
       "      <th>embed_vec5</th>\n",
       "      <th>embed_vec6</th>\n",
       "      <th>embed_vec7</th>\n",
       "      <th>...</th>\n",
       "      <th>embed_vec301</th>\n",
       "      <th>embed_vec302</th>\n",
       "      <th>embed_vec303</th>\n",
       "      <th>embed_vec304</th>\n",
       "      <th>embed_vec305</th>\n",
       "      <th>embed_vec306</th>\n",
       "      <th>embed_vec307</th>\n",
       "      <th>embed_vec308</th>\n",
       "      <th>embed_vec309</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.2966101694915254</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.20245825</td>\n",
       "      <td>0.046511000000000004</td>\n",
       "      <td>0.26283999999999996</td>\n",
       "      <td>-0.17235974999999998</td>\n",
       "      <td>0.04502025</td>\n",
       "      <td>0.050136</td>\n",
       "      <td>-0.016426999999999997</td>\n",
       "      <td>0.1393435</td>\n",
       "      <td>-0.13752050000000002</td>\n",
       "      <td>-0.12840625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.3050847457627119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.132496</td>\n",
       "      <td>-0.009801</td>\n",
       "      <td>0.31007</td>\n",
       "      <td>-0.178832</td>\n",
       "      <td>-0.138072</td>\n",
       "      <td>0.256234</td>\n",
       "      <td>-0.132928</td>\n",
       "      <td>0.205226</td>\n",
       "      <td>0.038524</td>\n",
       "      <td>-0.138742</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.3050847457627119</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018475000000000005</td>\n",
       "      <td>-0.141793</td>\n",
       "      <td>0.16553800000000002</td>\n",
       "      <td>0.077155</td>\n",
       "      <td>-0.2430875</td>\n",
       "      <td>-0.1152685</td>\n",
       "      <td>-0.0830385</td>\n",
       "      <td>-0.16332</td>\n",
       "      <td>0.1618245</td>\n",
       "      <td>0.044875000000000005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.3135593220338983</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010840999999999998</td>\n",
       "      <td>0.08353975</td>\n",
       "      <td>0.106417</td>\n",
       "      <td>-0.04024899999999999</td>\n",
       "      <td>0.064595</td>\n",
       "      <td>-0.011732000000000001</td>\n",
       "      <td>-0.19003875</td>\n",
       "      <td>0.03784</td>\n",
       "      <td>0.005795250000000002</td>\n",
       "      <td>-0.07896399999999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.3559322033898305</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.199834</td>\n",
       "      <td>-0.04717</td>\n",
       "      <td>0.157169</td>\n",
       "      <td>-0.075038</td>\n",
       "      <td>-0.148919</td>\n",
       "      <td>0.013595</td>\n",
       "      <td>-0.008292</td>\n",
       "      <td>-0.079288</td>\n",
       "      <td>-0.043639</td>\n",
       "      <td>0.127146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 313 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  patient_id visit_id          embed_vec0 embed_vec1 embed_vec2 embed_vec3  \\\n",
       "0          1        1  0.2966101694915254        1.0        0.0        0.0   \n",
       "1          1        2  0.3050847457627119        1.0        0.0        0.0   \n",
       "2          1        3  0.3050847457627119        1.0        0.0        0.0   \n",
       "3          1        4  0.3135593220338983        1.0        0.0        0.0   \n",
       "4          2        1  0.3559322033898305        0.0        1.0        0.0   \n",
       "\n",
       "  embed_vec4 embed_vec5 embed_vec6 embed_vec7  ...           embed_vec301  \\\n",
       "0        0.0        0.0        0.0        0.0  ...             0.20245825   \n",
       "1        0.0        0.0        0.0        0.0  ...               0.132496   \n",
       "2        0.0        0.0        0.0        0.0  ...  -0.018475000000000005   \n",
       "3        0.0        0.0        0.0        0.0  ...  -0.010840999999999998   \n",
       "4        0.0        0.0        1.0        0.0  ...              -0.199834   \n",
       "\n",
       "           embed_vec302         embed_vec303          embed_vec304  \\\n",
       "0  0.046511000000000004  0.26283999999999996  -0.17235974999999998   \n",
       "1             -0.009801              0.31007             -0.178832   \n",
       "2             -0.141793  0.16553800000000002              0.077155   \n",
       "3            0.08353975             0.106417  -0.04024899999999999   \n",
       "4              -0.04717             0.157169             -0.075038   \n",
       "\n",
       "  embed_vec305           embed_vec306           embed_vec307 embed_vec308  \\\n",
       "0   0.04502025               0.050136  -0.016426999999999997    0.1393435   \n",
       "1    -0.138072               0.256234              -0.132928     0.205226   \n",
       "2   -0.2430875             -0.1152685             -0.0830385     -0.16332   \n",
       "3     0.064595  -0.011732000000000001            -0.19003875      0.03784   \n",
       "4    -0.148919               0.013595              -0.008292    -0.079288   \n",
       "\n",
       "           embed_vec309                 label  \n",
       "0  -0.13752050000000002           -0.12840625  \n",
       "1              0.038524             -0.138742  \n",
       "2             0.1618245  0.044875000000000005  \n",
       "3  0.005795250000000002  -0.07896399999999999  \n",
       "4             -0.043639              0.127146  \n",
       "\n",
       "[5 rows x 313 columns]"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 10: Create the binary classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "properties = list(df.columns.values)\n",
    "X = df[properties[2:-1]]\n",
    "y = df['label']\n",
    "print(X.shape, len(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "616/616 [==============================] - 3s 5ms/step - loss: 1.5677 - accuracy: 0.4090 - val_loss: 1.5285 - val_accuracy: 0.4233\n",
      "Epoch 2/10\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 1.5159 - accuracy: 0.4304 - val_loss: 1.5242 - val_accuracy: 0.4204\n",
      "Epoch 3/10\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 1.5012 - accuracy: 0.4346 - val_loss: 1.5136 - val_accuracy: 0.4286\n",
      "Epoch 4/10\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 1.4909 - accuracy: 0.4381 - val_loss: 1.5137 - val_accuracy: 0.4247\n",
      "Epoch 5/10\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 1.4806 - accuracy: 0.4427 - val_loss: 1.5101 - val_accuracy: 0.4310\n",
      "Epoch 6/10\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 1.4702 - accuracy: 0.4459 - val_loss: 1.5184 - val_accuracy: 0.4233\n",
      "Epoch 7/10\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 1.4587 - accuracy: 0.4489 - val_loss: 1.5163 - val_accuracy: 0.4426\n",
      "Epoch 8/10\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 1.4465 - accuracy: 0.4549 - val_loss: 1.5141 - val_accuracy: 0.4377\n",
      "Epoch 9/10\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 1.4304 - accuracy: 0.4611 - val_loss: 1.5269 - val_accuracy: 0.4319\n",
      "Epoch 10/10\n",
      "616/616 [==============================] - 2s 4ms/step - loss: 1.4132 - accuracy: 0.4687 - val_loss: 1.5280 - val_accuracy: 0.4310\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Flatten(input_shape=(X.shape[1],)),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(16, activation=tf.nn.relu),\n",
    "    keras.layers.Dense(1, activation=tf.nn.sigmoid),\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=128)\n",
    "\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print('Test accuracy:', test_acc)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
