{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS 271 Project Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from numpy import asarray\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import gensim.downloader as api\n",
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "import csv\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read in relevant Data Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make sure the files below are in the same directory as your jupyter file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants\n",
    "PATIENT_DATA_FILE = 'B220_SAA_v1.csv'\n",
    "CLEANED_LABELS_FILE = 'ICD_Label_Cleaned_Oct_25.csv'\n",
    "CODE_DESC_FILE = 'BIODS220_ICD_Dx_10_9_v7 - icd_dx_10_9_v7.csv'\n",
    "# May want to consider: glove-wiki-gigaword-100 in the future\n",
    "# See more here: https://github.com/RaRe-Technologies/gensim-data\n",
    "LANG_MODEL = 'word2vec-google-news-300'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_csv_to_dict(file_path: str, key: int, value: int):\n",
    "    ret_dict = {}\n",
    "    with open(file_path, newline='') as csvfile:\n",
    "        data = csv.reader(csvfile, delimiter=',')\n",
    "        for row in data:\n",
    "            ret_dict[row[key]] = row[value]\n",
    "    print(\"Reading {} complete!\".format(file_path))\n",
    "    return ret_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_category_dict():\n",
    "    category_dict = {\n",
    "        'Circulatory': 1,\n",
    "        'Dermatologic': 2,\n",
    "        'Endocrine & Immune': 3,\n",
    "        'Gastrointestinal': 4,\n",
    "        'Genitourinary': 5, \n",
    "        'Hematologic': 6,\n",
    "        'Infectious': 7,\n",
    "        'Injury': 8,\n",
    "        'Injury & Poisoning': 9,\n",
    "        'Musculoskeletal': 10,\n",
    "        'Neurologic': 11,\n",
    "        'Other': 12,\n",
    "        'Obstetric': 13,\n",
    "        'Neoplastic': 14,\n",
    "        'Poisoning': 15,\n",
    "        'Psychiatric': 16,\n",
    "        'Respiratory': 17,\n",
    "        'Substance use': 18}\n",
    "    return category_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import word to vec model\n",
    "wv = api.load(LANG_MODEL)\n",
    "print(\"Reading {} complete!\".format(LANG_MODEL))\n",
    "\n",
    "# Create labels dict i.e. code -> label\n",
    "label_dict = read_csv_to_dict(CLEANED_LABELS_FILE, key=0, value=1)\n",
    "\n",
    "# Create descriptions dict i.e. code -> description\n",
    "codes_dict = read_csv_to_dict(CODE_DESC_FILE, key=0, value=2)\n",
    "\n",
    "# Create dict for label to int\n",
    "category_dict = get_category_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create one-hot feature vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the sake of reducing feature space, we are only including three features in our embedding. Future iterations of our embeddings will include more features, such as the patient's county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_one_hot(patient_data):\n",
    "    # Creates one-hot vectors\n",
    "    columns_to_one_hot = ['Sex','Race']\n",
    "    one_hot = pd.get_dummies(patient_data[columns_to_one_hot])\n",
    "    \n",
    "    ordinal_columns = ['Age']\n",
    "    one_hot = pd.concat([patient_data[ordinal_columns], one_hot], axis=1)\n",
    "    \n",
    "    # Normalize age\n",
    "    x = one_hot.Age.values.reshape(-1,1)\n",
    "    min_max_scaler = preprocessing.MinMaxScaler()\n",
    "    x_scaled = min_max_scaler.fit_transform(x)\n",
    "    one_hot.Age = x_scaled\n",
    "    \n",
    "    return one_hot.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in patient_data\n",
    "patient_read_start = time.time()\n",
    "patient_data = pd.read_csv(PATIENT_DATA_FILE, dtype=str, usecols=['Sex','Race','Age','Dx10_prin'])\n",
    "print(\"Reading in patient_data took {}\".format(time.time() - patient_read_start))\n",
    "\n",
    "# One-hot encode visit features\n",
    "one_hot_start = time.time()\n",
    "one_hot = create_one_hot(patient_data)\n",
    "print(\"Creating one-hot encodings took {}\".format(time.time() - one_hot_start))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 3: Embed ICD Codes + concat with one-hot vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a sentence, retrieve the pre-trained word2vec embedding for each word in the sentence and return the mean of the embeddings. If the sentence has no words that exist in the word2vec model, we return None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_sentence(sentence, split_tokens):\n",
    "    word_embeddings = []\n",
    "    for word in re.split(split_tokens, sentence):\n",
    "        try:\n",
    "            word_embeddings.append(wv[word.lower()])\n",
    "        except KeyError:\n",
    "            continue\n",
    "    if len(word_embeddings)>0:\n",
    "        return np.mean(word_embeddings, axis=0)\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a sentence and label, return the embedding of a sentence. If there is no embedding for the sentence then return the embedding for the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_w2v_embedding(sentence, label):\n",
    "    \"\"\"\n",
    "    Sentence: A description of an ICD10 code, usually 1-5 words\n",
    "    Category: The class of the diagnosis, one of 17 options\n",
    "    \"\"\"\n",
    "    embedding = embed_sentence(sentence, split_tokens='\\s|(?<!\\d)[:;,.\\(\\)\\[\\]-](?!\\d)')\n",
    "    \n",
    "    # If we can't create embedding with ICD10 codes, we use category\n",
    "    if embedding is not None:\n",
    "        return embedding\n",
    "    else:\n",
    "        return embed_sentence(label, split_tokens='\\s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an ICD code, return the corresponding description. Here, we attempt to take handle mistyped data. Some codes are missing 1-2 characters. Sometimes, adding a 0 or removing the last character in a code will fix typos, however this strategy is prone to error and not guarunteed to work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_desc(code):\n",
    "    try:\n",
    "        desc = codes_dict[code]\n",
    "    except KeyError:\n",
    "        try:\n",
    "            new_code = code + '0'\n",
    "            desc = codes_dict[new_code]\n",
    "        except:\n",
    "            try:\n",
    "                new_code = code[:-1]\n",
    "                desc = codes_dict[new_code]\n",
    "            except:\n",
    "                desc = 'Other'\n",
    "    try:\n",
    "        label = labels_dict[code]\n",
    "    except:\n",
    "        label = 'Other'\n",
    "    return desc, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given an ICD code, we retrieve the embedding (300x1). We use dynamic programming to save embeddings. Often, only the first three characters of an ICD code are enough to determine the general diagnosis. Longer codes will only have slightly different descriptions (if at all). Thus, to reduce computational complexity, we store the first three characters of ICD codes. Future ICD codes that share the same first three characters will automatically use the same embedding, regardless of any remaining characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "descriptions_dict = {}\n",
    "def code_to_embedding(code):\n",
    "    try:\n",
    "        embedding = descriptions_dict[str(code[:3])]\n",
    "    except:\n",
    "        desc, category = get_desc(code)\n",
    "        embedding = get_w2v_embedding(desc, category)\n",
    "        if desc is not 'Other':\n",
    "            descriptions_dict[str(code[:3])] = embedding\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each row of ICD Codes (i.e ['E839', 'SA920']), we retrieve the corresponding embeddings. For patient visits with n ICD Codes where n>1, we give 0.75 weight to the primary ICD code and 0.25/n-1 weight to the remaining (secondary) codes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRIMARY_WEIGHT = 0.75\n",
    "SECONDARY_WEIGHT = 0.25\n",
    "\n",
    "def row_to_embedding(input_row):\n",
    "    \"\"\"\n",
    "    input_row: A list of ICD10 codes\n",
    "    returns a 300x1 embedding\n",
    "    \"\"\"\n",
    "    n = len(input_row)\n",
    "    code = input_row[0]\n",
    "    # Primary ICD code:\n",
    "    primary_embedding = code_to_embedding(code)\n",
    "    if n < 2: return primary_embedding\n",
    "    \n",
    "    # Subsequent ICD codes:\n",
    "    secondary_embedding = None\n",
    "    for i in range(1, n):\n",
    "        code = input_row[i]\n",
    "        curr_embed = code_to_embedding(code)\n",
    "        if secondary_embedding is None:\n",
    "            secondary_embedding = curr_embed\n",
    "        else:\n",
    "            secondary_embedding = np.sum([secondary_embedding, curr_embed], axis=0)\n",
    "    return np.sum([primary_embedding * PRIMARY_WEIGHT, secondary_embedding * (SECONDARY_WEIGHT/n-1)], axis=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the patient visit csv file again and create embeddings for each visit as we read the file. For each visit, we have already computed the one-hot vector encoding for categorical and ordinal variables. Here, we combine those encodings with ICD_10 code embeddings. To reduce model complexity, we limit the number of patients (not total visits) for which to create embeddings. Here, we are working under the assumption that all visits for a patient appear one after the other in the csv file, thus, we can stop reading from the file once `patient id > num_patients`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_PATIENTS = 1e6\n",
    "\n",
    "def get_visit_embedding(input_file_path: str):\n",
    "    start_time = time.time()\n",
    "    embeddings = []\n",
    "    max_len = 0\n",
    "    with open(input_file_path, newline='') as csvfile:\n",
    "        data = csv.reader(csvfile, delimiter=',')\n",
    "        count = 0\n",
    "        for row in data:\n",
    "            if count == 0: # Skip the first row\n",
    "                count += 1\n",
    "                continue\n",
    "            \n",
    "            if int(row[0]) > NUM_PATIENTS: # Used to limit num patients, reducing model space\n",
    "                break\n",
    "            ICD_code_embeddings = row_to_embedding([entry for entry in row[16:41] if entry is not ''])\n",
    "            visit_embedding = np.concatenate((one_hot[count-1, :], ICD_code_embeddings), axis=0)\n",
    "            embeddings.append(visit_embedding)\n",
    "            if count % 250000 == 0:\n",
    "                print(\"Completed {} visit embeddings in {}\".format(count, (time.time() - start_time)))\n",
    "            count +=1\n",
    "    print(\"Shape of embeddings: ({},{})\".format(len(embeddings), len(embeddings[0])))\n",
    "    return np.array(embeddings), count-1\n",
    "\n",
    "embedding_dset, num_visits = get_visit_embedding(PATIENT_DATA_FILE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Get labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create labels, we copy the primary diagnosis codes (`DX10_prin` column) into its own column named `Label`. For each code, we use the `label_dict` to retrive the corresponding category of the ICD code. Then we use the `category_dict` to retieve a number to represent the label. We limit the number of visits to the same size as the number of embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_Dx10_prin_to_label(DX_10_code):\n",
    "    try:\n",
    "        category = label_dict[DX_10_code] # i.e. A065 -> Infectious\n",
    "    except KeyError:\n",
    "        category = 'Other'\n",
    "    return category_dict[category] # i.e. Infectious -> 7 \n",
    "\n",
    "def get_y_labels(patient_data):\n",
    "    # Copy Dx10 code into new column named Label\n",
    "    patient_data['Label'] = patient_data.Dx10_prin\n",
    "\n",
    "    # Apply function to Label column to convert Dx10_prin code to category\n",
    "    patient_data.Label = patient_data.Label.apply(convert_Dx10_prin_to_label)\n",
    "    \n",
    "    # Saves only the top num_visits, since that's how many embeddings there are\n",
    "    y_list = patient_data.Label.iloc[:num_visits].to_list()\n",
    "    return np.array(y_list), len(y_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get y_dset\n",
    "label_start = time.time()\n",
    "y_dset, num_labels = (get_y_labels(patient_data))\n",
    "print(\"Creating labels took {}\".format(time.time() - label_start))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensures the number of labels corresponds to the number of patient visits\n",
    "assert(num_labels == num_visits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Save embeddings and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'embeddings_{}.pickle'.format(LANG_MODEL)\n",
    "\n",
    "start_time = time.time()\n",
    "pickle_out = open(filename, 'wb')\n",
    "pickle.dump((embedding_dset, y_dset), pickle_out, protocol=4)\n",
    "pickle_out.close\n",
    "print(\"Saving embeddings took: {}\".format(time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
