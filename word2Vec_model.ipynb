{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "balanced-command",
   "metadata": {},
   "source": [
    "# Word2Vec Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "provincial-rabbit",
   "metadata": {},
   "source": [
    "This file contains the code necessary to train and test on a model using word2vec embeddings. Please refer to `word2vec_embeddings` to see how the embeddings were trained."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "connected-responsibility",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "import random\n",
    "import pickle\n",
    "import csv\n",
    "import collections\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "resistant-apartment",
   "metadata": {},
   "source": [
    "## Step 0: Initialize PySpark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hired-aquarium",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark import SparkContext, SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "stupid-passenger",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'35G'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create the session\n",
    "conf = SparkConf().set(\"spark.ui.port\", \"4050\")\n",
    "conf = (conf.setMaster('local[*]')\n",
    "        .set('spark.executor.memory', '35G')\n",
    "        .set('spark.driver.memory', '35G')\n",
    "        .set('spark.driver.maxResultSize', '35G'))\n",
    "# create the context\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "spark.conf.set(\"spark.sql.execution.arrow.enabled\", \"true\")\n",
    "# arrow enabling is what makes the conversion from pandas to spark dataframe really fast\n",
    "sc._conf.get('spark.driver.memory')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "figured-denial",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://ip-172-31-33-175.us-west-2.compute.internal:4050\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.1.1</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fadc04267d0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "directed-headset",
   "metadata": {},
   "source": [
    "## Step 1: Read in relevant data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "moral-episode",
   "metadata": {},
   "outputs": [],
   "source": [
    "dirPath = '/home/ubuntu/Biomed-Data-Science-NLP-Project/Data/'\n",
    "embedFilePath = dirPath + 'pyspark_w2v_embeddingSize_100'\n",
    "corpusFilePath = dirPath + 'train_stringed_CCSR_sentences.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bottom-laser",
   "metadata": {},
   "source": [
    "### Read in embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "stone-robinson",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "502"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.feature import Tokenizer\n",
    "from pyspark.ml.feature import Word2Vec, Word2VecModel\n",
    "from pyspark.ml import Pipeline\n",
    "loaded_model = Word2VecModel.load(embedFilePath)\n",
    "df_embeddings = loaded_model.getVectors()\n",
    "df_embeddings.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "structured-flour",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------+--------------------+\n",
      "|  word|              vector|\n",
      "+------+--------------------+\n",
      "|inj029|[-0.2791734635829...|\n",
      "|skn005|[0.13488520681858...|\n",
      "|inj033|[-0.1691723316907...|\n",
      "|inj070|[-0.3290005326271...|\n",
      "|nvs003|[-0.2571149170398...|\n",
      "|cir002|[-0.2463666051626...|\n",
      "|nvs018|[0.13281399011611...|\n",
      "|ear002|[0.54433143138885...|\n",
      "|neo028|[-0.0892063081264...|\n",
      "|cir017|[-0.0426498651504...|\n",
      "|neo039|[0.08893523365259...|\n",
      "|inj050|[0.54959970712661...|\n",
      "|ext014|[0.30336469411849...|\n",
      "|inj074|[-0.0489733181893...|\n",
      "|prg028|[0.29435864090919...|\n",
      "|inj044|[0.34294834733009...|\n",
      "|gen020|[-0.2292252480983...|\n",
      "|dig018|[0.30665281414985...|\n",
      "|cir039|[0.07407408207654...|\n",
      "|pnl010|[0.08308684080839...|\n",
      "+------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_embeddings.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appreciated-model",
   "metadata": {},
   "source": [
    "### Read in trian corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "necessary-haiti",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(corpusFilePath, 'rb') as handle:\n",
    "    corpus = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "final-harris",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18.766186 million visits\n"
     ]
    }
   ],
   "source": [
    "print(\"{} million visits\".format(len(corpus)/1e6))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "electronic-cursor",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           sentences|\n",
      "+--------------------+\n",
      "|MBD012 MBD001 MBD002|\n",
      "|PRG028 SYM004 SYM...|\n",
      "|SYM006 FAC021 FAC021|\n",
      "|CIR009 CIR019 CIR...|\n",
      "|RSP008 SYM010 CIR...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_corpus = pd.DataFrame(corpus, columns = ['sentences'])\n",
    "df_corpus = spark.createDataFrame(df_corpus)\n",
    "df_corpus.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "faced-fight",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|              tokens|\n",
      "+--------------------+\n",
      "|[mbd012, mbd001, ...|\n",
      "|[prg028, sym004, ...|\n",
      "|[sym006, fac021, ...|\n",
      "|[cir009, cir019, ...|\n",
      "|[rsp008, sym010, ...|\n",
      "+--------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "18766186"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(inputCol=\"sentences\", outputCol=\"tokens\")\n",
    "tokenized_corpus = tokenizer.transform(df_corpus).select(\"tokens\")\n",
    "tokenized_corpus.show(5)\n",
    "tokenized_corpus.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "combined-taylor",
   "metadata": {},
   "source": [
    "### Read in train data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "working-indie",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18766186"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = spark.read.load(dirPath + \"train\",\n",
    "                     format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n",
    "train.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rational-chapel",
   "metadata": {},
   "source": [
    "### Read in test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "rough-shell",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4691547"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = spark.read.load(dirPath + \"test\",\n",
    "                     format=\"csv\", sep=\",\", inferSchema=\"true\", header=\"true\")\n",
    "test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "joined-decade",
   "metadata": {},
   "source": [
    "## Turn Corpus into embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "cloudy-holmes",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|              tokens|            features|\n",
      "+--------------------+--------------------+\n",
      "|[mbd012, mbd001, ...|[0.04541126700739...|\n",
      "|[prg028, sym004, ...|[0.11673879437148...|\n",
      "|[sym006, fac021, ...|[-0.1344170595208...|\n",
      "|[cir009, cir019, ...|[0.05347454361617...|\n",
      "|[rsp008, sym010, ...|[-0.0048551074827...|\n",
      "|    [gen017, gen017]|[0.05020602792501...|\n",
      "|    [mus025, mus010]|[0.06714359391480...|\n",
      "|            [mbd005]|[-0.1537506878376...|\n",
      "|            [cir012]|[0.28262704610824...|\n",
      "|[inj011, inj027, ...|[0.20975265997861...|\n",
      "|    [sym011, cir007]|[0.11789469188079...|\n",
      "|            [fac025]|[-0.1113107800483...|\n",
      "|[gen004, cir007, ...|[0.07823335627714...|\n",
      "|[dig021, gen002, ...|[-0.0201907082726...|\n",
      "|[fac001, inj017, ...|[0.08521811524406...|\n",
      "|[mus026, inj030, ...|[0.02278881277889...|\n",
      "|            [inj017]|[0.02689004875719...|\n",
      "|    [dig002, fac025]|[0.31509736180305...|\n",
      "|[inj003, cir012, ...|[-0.0570662468671...|\n",
      "|            [rsp003]|[0.37611550092697...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "res = loaded_model.transform(tokenized_corpus)\n",
    "res.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "foster-recognition",
   "metadata": {},
   "source": [
    "## Add demographic information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stainless-rubber",
   "metadata": {},
   "source": [
    "- May need to move to 100 dimensional vector\n",
    "- Think of some spark methods to use\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "numeric-reference",
   "metadata": {},
   "source": [
    "## Section to hopefully be replaced by word2Vec outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "figured-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "27977932it [01:11, 391447.87it/s]\n"
     ]
    }
   ],
   "source": [
    "def get_word_index():\n",
    "    dirPath = '/home/ubuntu/Biomed-Data-Science-NLP-Project/Data/'\n",
    "    CCSR_filepath = dirPath + 'ICD_to_CCSR_20201_1.csv'\n",
    "    \n",
    "    icd_to_ccsr_code = {} # Maps icd_code to ccsr_code\n",
    "    with open(CCSR_filepath, newline='') as csvfile:\n",
    "        data = csv.reader(csvfile, delimiter=',')\n",
    "        for row in data:\n",
    "            icd_to_ccsr_code[row[0][1:-1]] = row[6][1:-1]\n",
    "    \n",
    "    word_counts = collections.defaultdict(int)\n",
    "    for i, sentence in tqdm(enumerate(corpus)):\n",
    "        if len(sentence) == 1: continue\n",
    "        for ICD_code in sentence:\n",
    "            try:\n",
    "                ccsr_code = icd_to_ccsr_code[ICD_code]\n",
    "                word_counts[ccsr_code] += 1\n",
    "            except:\n",
    "                pass\n",
    "    # Generate word:index\n",
    "    words_list = list(word_counts.keys())\n",
    "    word_index = dict((word, i) for i, word in enumerate(words_list))\n",
    "    return word_index\n",
    "word_index = get_word_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ideal-aside",
   "metadata": {},
   "source": [
    "## Step 2: Read in patient data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "restricted-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_patient_data():\n",
    "    dirPath = '/home/ubuntu/Biomed-Data-Science-NLP-Project/Data/'\n",
    "    patient_data_filepath = dirPath + 'B220_SAA_v1.csv'\n",
    "    df = pd.read_csv(patient_data_filepath, dtype=str, usecols=[0, 3, 5, 6, 7] + list(range(16,41)))\n",
    "    return df\n",
    "patient_data = read_patient_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "roman-commodity",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Date</th>\n",
       "      <th>Age</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Race</th>\n",
       "      <th>Dx10_prin</th>\n",
       "      <th>Dx10_1</th>\n",
       "      <th>Dx10_2</th>\n",
       "      <th>Dx10_3</th>\n",
       "      <th>Dx10_4</th>\n",
       "      <th>...</th>\n",
       "      <th>Dx10_15</th>\n",
       "      <th>Dx10_16</th>\n",
       "      <th>Dx10_17</th>\n",
       "      <th>Dx10_18</th>\n",
       "      <th>Dx10_19</th>\n",
       "      <th>Dx10_20</th>\n",
       "      <th>Dx10_21</th>\n",
       "      <th>Dx10_22</th>\n",
       "      <th>Dx10_23</th>\n",
       "      <th>Dx10_24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2016-06-05</td>\n",
       "      <td>35</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>S300XXA</td>\n",
       "      <td>M542</td>\n",
       "      <td>S199XXA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-07-16</td>\n",
       "      <td>36</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>N938</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2017-08-15</td>\n",
       "      <td>36</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>F10129</td>\n",
       "      <td>N390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2018-07-12</td>\n",
       "      <td>37</td>\n",
       "      <td>F</td>\n",
       "      <td>White</td>\n",
       "      <td>R0789</td>\n",
       "      <td>R0602</td>\n",
       "      <td>F17210</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2015-12-29</td>\n",
       "      <td>42</td>\n",
       "      <td>M</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>N390</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27977927</th>\n",
       "      <td>14493203</td>\n",
       "      <td>2017-08-07</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>R509</td>\n",
       "      <td>J111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27977928</th>\n",
       "      <td>14493203</td>\n",
       "      <td>2017-11-24</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>S53002A</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27977929</th>\n",
       "      <td>14493203</td>\n",
       "      <td>2018-01-21</td>\n",
       "      <td>1</td>\n",
       "      <td>F</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>R112</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27977930</th>\n",
       "      <td>14493203</td>\n",
       "      <td>2018-07-28</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>R509</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27977931</th>\n",
       "      <td>14493203</td>\n",
       "      <td>2018-08-27</td>\n",
       "      <td>2</td>\n",
       "      <td>F</td>\n",
       "      <td>Hispanic</td>\n",
       "      <td>Z711</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>27977932 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                ID        Date Age Sex      Race Dx10_prin Dx10_1   Dx10_2  \\\n",
       "0                1  2016-06-05  35   F     White   S300XXA   M542  S199XXA   \n",
       "1                1  2017-07-16  36   F     White      N938    NaN      NaN   \n",
       "2                1  2017-08-15  36   F     White    F10129   N390      NaN   \n",
       "3                1  2018-07-12  37   F     White     R0789  R0602   F17210   \n",
       "4                2  2015-12-29  42   M  Hispanic      N390    NaN      NaN   \n",
       "...            ...         ...  ..  ..       ...       ...    ...      ...   \n",
       "27977927  14493203  2017-08-07   1   F  Hispanic      R509   J111      NaN   \n",
       "27977928  14493203  2017-11-24   1   F  Hispanic   S53002A    NaN      NaN   \n",
       "27977929  14493203  2018-01-21   1   F  Hispanic      R112    NaN      NaN   \n",
       "27977930  14493203  2018-07-28   2   F  Hispanic      R509    NaN      NaN   \n",
       "27977931  14493203  2018-08-27   2   F  Hispanic      Z711    NaN      NaN   \n",
       "\n",
       "         Dx10_3 Dx10_4  ... Dx10_15 Dx10_16 Dx10_17 Dx10_18 Dx10_19 Dx10_20  \\\n",
       "0           NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "1           NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "2           NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "3           NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "4           NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "...         ...    ...  ...     ...     ...     ...     ...     ...     ...   \n",
       "27977927    NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "27977928    NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "27977929    NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "27977930    NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "27977931    NaN    NaN  ...     NaN     NaN     NaN     NaN     NaN     NaN   \n",
       "\n",
       "         Dx10_21 Dx10_22 Dx10_23 Dx10_24  \n",
       "0            NaN     NaN     NaN     NaN  \n",
       "1            NaN     NaN     NaN     NaN  \n",
       "2            NaN     NaN     NaN     NaN  \n",
       "3            NaN     NaN     NaN     NaN  \n",
       "4            NaN     NaN     NaN     NaN  \n",
       "...          ...     ...     ...     ...  \n",
       "27977927     NaN     NaN     NaN     NaN  \n",
       "27977928     NaN     NaN     NaN     NaN  \n",
       "27977929     NaN     NaN     NaN     NaN  \n",
       "27977930     NaN     NaN     NaN     NaN  \n",
       "27977931     NaN     NaN     NaN     NaN  \n",
       "\n",
       "[27977932 rows x 30 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "patient_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "correct-discount",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_y_dset(patient_data):\n",
    "    patient_data.loc[:,'Date'] = pd.to_datetime(patient_data.loc[:,'Date'])\n",
    "    y_diff = abs(patient_data.groupby(by='ID')['Date'].diff(periods=-1)).dt.days\n",
    "    y_dset = y_diff.to_numpy()\n",
    "    y_dset = np.where(y_dset <= 30, 1, y_dset)\n",
    "    y_dset = np.where(y_dset > 30, 0, y_dset)\n",
    "    y_dset = np.where(np.isnan(y_dset), 2, y_dset)\n",
    "    return y_dset\n",
    "start = time.time()\n",
    "y_dset = get_y_dset(patient_data.iloc[:, [0,1]])\n",
    "end = time.time()\n",
    "print(\"Took {} seconds\".format(end - start))\n",
    "y_dset.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-genealogy",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cellular-participant",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rational-pharmaceutical",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "operational-pattern",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-fountain",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "agricultural-young",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "cannot unpack non-iterable NoneType object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-104-2a5351a50119>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0my_dset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_y_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: cannot unpack non-iterable NoneType object"
     ]
    }
   ],
   "source": [
    "def get_y_labels(patient_data):\n",
    "    patient_data['Date'] = pd.to_datetime(patient_data['Date'])\n",
    "\n",
    "\n",
    "y_dset, num_labels = get_y_labels(patient_data.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "sensitive-ethnic",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-103-519ed8cb2e35>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0my_label\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_label\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0my_dset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_y_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-103-519ed8cb2e35>\u001b[0m in \u001b[0;36mget_y_labels\u001b[0;34m(patient_data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_y_labels\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mpatient_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_datetime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m#convert date column to date-time type\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0my_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatient_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mperiods\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0my_diff\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_diff\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0my_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    815\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 817\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcurried\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_obj_with_exclusions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    818\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    819\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f, data)\u001b[0m\n\u001b[1;32m    926\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0mafter\u001b[0m \u001b[0mapplying\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \"\"\"\n\u001b[0;32m--> 928\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m         return self._wrap_applied_output(\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    218\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    221\u001b[0m             \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"name\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 980\u001b[0;31m             \u001b[0;32myield\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_chop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mslice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_sorted_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mFrameOrSeries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36m_chop\u001b[0;34m(self, sdata, slice_obj)\u001b[0m\n\u001b[1;32m    992\u001b[0m         \u001b[0mmgr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mgr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_slice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mslice_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    993\u001b[0m         \u001b[0;31m# __finalize__ not called here, must be applied by caller if applicable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 994\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_constructor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmgr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfastpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    995\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    996\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    246\u001b[0m             \u001b[0;31m# GH#33357 called with just the SingleBlockManager\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mNDFrame\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m             \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__setattr__\u001b[0;34m(self, name, value)\u001b[0m\n\u001b[1;32m   5462\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5463\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5464\u001b[0;31m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5465\u001b[0m         \"\"\"\n\u001b[1;32m   5466\u001b[0m         \u001b[0mAfter\u001b[0m \u001b[0mregular\u001b[0m \u001b[0mattribute\u001b[0m \u001b[0maccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mtry\u001b[0m \u001b[0msetting\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def get_y_labels(patient_data):\n",
    "    patient_data['Date'] = pd.to_datetime(patient_data['Date'])  #convert date column to date-time type\n",
    "    y_diff = abs(patient_data.groupby(['ID'])['Date'].diff(periods=-1))\n",
    "    y_diff = y_diff.dt.days\n",
    "    y_label = []\n",
    "    for i in y_diff:\n",
    "        if pd.isnull(i):\n",
    "            y_label.append(2)\n",
    "        else:\n",
    "            if i <= 30:\n",
    "                y_label.append(1)\n",
    "            else:\n",
    "                y_label.append(0)\n",
    "    return y_label, len(y_label)\n",
    "y_dset, num_labels = get_y_labels(patient_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "legislative-influence",
   "metadata": {},
   "outputs": [],
   "source": [
    "-"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
